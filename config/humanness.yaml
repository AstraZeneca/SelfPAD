---
seed: 57
use_wandb: False
use_validation: False
root_path: ./
data_path: ./data
pretrained_checkpoint_path: ./results/pretraining/training/model/pretrained_model.ckpt
finetuned_checkpoint_path: ./results/humanness/training/model/transformer.ckpt


# Data related options
y_label: species
vocab_size: 10261
p_vocab: 0.2      # Proportion of the vocabulary to sample in each iteration
num_labels: 100   # Number of data points sampled. Keep it small
pad_index: 23     # Index of mask token in the vocabulary

# Model architecutre
max_seq_length: 180    # maximum sequence length
model_dim: 32
use_regression: false
mlp_output_dim: 2      # output dim of the classifier

# Data splits
training_data_ratio: 0.9  # Training vs valiation. 1.0==All is used for training i.e. no validation set
                          # Test set is provided seperately

# Hyper-parameters.
epochs: 25                        # Maximum number of epochs
learning_rate: 0.0001             # Learning rate for training
dropout_rate: 0.2                 # Set dropout rate if Dropout is being used
batch_size: 512                   # Set batch size
scheduler: false                  # If true, it will use scheduler for learning rate
val_check_interval: 100           # Intervals between each validation checks
validate: true

# Normalisation and Objective func.
cosine_similarity: False          # If True, use cosine similarity in NTXentLoss. Else, use dot product.
p_norm: 2                         # p-value used for normalization. p=2 for L2 norm, p=1 for L1 norm and so on.


# Losses to use
contrastive_loss: true
distance_loss: False

# Wheter to add noise
add_noise: true                  # Whether to add noise
input_shift: true                # Whether to apply input-shift noise
noise_type: swap                 # Whether to use swap noise. Else, it is gausian noise
noise_level: 0.15                # Scaler for gaussion noise if gaussian noise is used
noise_ratio: 0.2                 # Percentage of the sequence to add noise to
        
# Number of layers to re-initialize for pre-trained model
reinit_n_layers: 4

# Embedding
aggregate_on_sequence_dim: true  # Dimension to use when pooling the embeddings 
emb_layer: -1                    # Embedding layer to use

# Threshold to use when classifying for humanness
threshold: 0.03